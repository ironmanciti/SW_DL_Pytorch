{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUA64IUYOhHl"
   },
   "source": [
    "# 011. PyTorch Dataset\n",
    "\n",
    "### Dataset 클래스\n",
    "\n",
    " - PyTorch는 두 개의 데이터 관련 클라스를 제공하여 pre-loaded datasets 및 custom dataset 을 사용할 수 있도록 한다.\n",
    " \n",
    "     - torch.utils.data.Dataset - 샘플 및 해당 레이블을 제공\n",
    "     - torch.utils.data.DataLoader - 샘플에 쉽게 액세스 할 수 있도록 Dataset의 iterable 을 wrapping\n",
    "     \n",
    "\n",
    "- PyTorch domain library (Image, Text, Audio dataset) 들은 torch.utils.data.Dataset 을 상속 받은 pre-loaded dataset (ex. FashionMNIST)과 관련 함수 제공\n",
    " \n",
    "\n",
    "- torch.utils.data.Dataset 은 데이터셋을 나타내는 추상클래스이다.\n",
    "\n",
    "\n",
    "- custom 데이터셋은 Dataset 을 상속하고 아래와 같이 Dataset method 를 오버라이드 하여 작성\n",
    "\n",
    "\n",
    "    - 생성자 __init__ 은 dataset 의 전처리를 해주는 부분\n",
    "    - len(dataset) 에서 호출되는 __len__ 은 데이터셋의 크기를 리턴\n",
    "    - dataset[i] 에서 호출되는 __getitem__ 은 𝑖 번째 샘플을 찾는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNVqy1FbOhHt",
    "outputId": "0dda2bd2-246d-41b7-818a-de34438bc3cf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImddWZXJOhHw"
   },
   "source": [
    "## 사용자 정의 Dataset 작성\n",
    "\n",
    "- 특정 길이의 data를 생성하는 사용자 정의 Dataset class  \n",
    "- transform object를 전달 받으면 data 변환을 하여 반환  \n",
    "- iterable형태로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8V2qY4joOhHx"
   },
   "outputs": [],
   "source": [
    "class toy_set(Dataset):\n",
    "    def __init__(self, length=100, transform=None):\n",
    "        # reproducability\n",
    "        torch.manual_seed(101)\n",
    "        # dataset 을 전처리\n",
    "        self.x = 2 * torch.rand(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.len = length\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # idx 번째 sample 1 개를 가져오는 함수\n",
    "        sample = self.x[idx], self.y[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "            \n",
    "    def __len__(self):\n",
    "        # dataset의 길이를 반환\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmFtIvrxOhHy"
   },
   "source": [
    "### iterable 형태로 사용\n",
    "- len(dataset)  \n",
    "- dataset[ i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vekWIG4FOhHy",
    "outputId": "1c63ec35-1781-4ddd-b59b-a9ab44724739"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = toy_set()\n",
    "\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTIq0nQvOhHz",
    "outputId": "d81edf9c-edee-4144-b552-c3fffe426a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3961, 0.9006]) tensor([1.])\n",
      "tensor([0.1818, 1.7744]) tensor([1.])\n",
      "tensor([0.5788, 0.0372]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    x, y = test_data[i]\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Uw2nKvtOhH0",
    "outputId": "2618fd6e-7bd0-4d82-e2bd-5893d5c3d00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3961, 0.9006]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_data:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3961, 0.9006]), tensor([1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29t0psPgOhH1"
   },
   "source": [
    "## Transform 적용\n",
    "\n",
    "- 사용자 정의 transform module 을 Custom Dataset 에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5B50dQMOhH2"
   },
   "source": [
    "### Transform 함수 적용 예 : scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tFi6ti1jOhH2"
   },
   "outputs": [],
   "source": [
    "def scaling(sample):\n",
    "    x, y = sample\n",
    "    scaled_x = x / 10.\n",
    "    scaled_y = y / 10.\n",
    "    return scaled_x, scaled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9wFYNUhOhH3",
    "outputId": "577f3276-c612-4d9e-d9ff-8f30872bff22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1249, 0.0737]), tensor([0.1000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ = toy_set(10, transform=scaling)\n",
    "\n",
    "dataset_[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlxGcH6hOhH3"
   },
   "source": [
    "### transform class 적용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3PuiUsuvOhH4"
   },
   "outputs": [],
   "source": [
    "class add_one:\n",
    "    def __init__(self, added=1):\n",
    "        self.added = added\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        x = x + self.added\n",
    "        y = y + self.added\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "387FjPOBOhH4",
    "outputId": "00048e65-fb7c-4774-cd07-1467f6a6eb12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.2487, 1.7367]), tensor([2.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_m = add_one()\n",
    "\n",
    "dataset_ = toy_set(10, transform=a_m)\n",
    "dataset_[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFisAyhnOhH5"
   },
   "source": [
    "### Transform 을 동시에 여러개 적용 : transform.Compose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iag1dlFtOhH5"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "data_transform = transforms.Compose([scaling, add_one()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBOMrqu2OhH6",
    "outputId": "3ec86733-b7cc-4477-b783-da5178fdc845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3961, 0.9006]), tensor([1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = toy_set(5)\n",
    "next(iter(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0396, 1.0901]), tensor([1.1000]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = toy_set(5, transform=data_transform)\n",
    "next(iter(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWID8_6yOhH7"
   },
   "source": [
    "<h1>pre-built Datasets and Transforms</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rdLNw5A-OhH8"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "j7FA9WoVOhH9"
   },
   "outputs": [],
   "source": [
    "croptensor_data_transform = transforms.Compose(\n",
    "                    [transforms.CenterCrop(20), transforms.ToTensor()])\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=croptensor_data_transform\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=croptensor_data_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0iaD_nyOhH9",
    "outputId": "526b7f0f-ecfa-401e-8495-f871f58627b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ZmHJ6mrROhH-",
    "outputId": "429ac829-241c-4dac-944f-a77dcd26422c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_data[0][0].view(20, 20), cmap=\"gray\")\n",
    "plt.title(\"y = {}\".format(training_data[0][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HAG7FNTOhH-"
   },
   "source": [
    "## DataLoader를 사용하여 training 데이터 준비\n",
    "\n",
    "Dataset은 `한 번에 한개 씩 샘플`의 feature 와 label 을 retreive 합니다. 모델을 훈련하는 동안 일반적으로 `minibatch`로 샘플을 전달하고, 매 epoch 마다 데이터를 reshuffle 하여 overfitting을 줄이며, Python의 multiprocessing을 사용하여 읽는 속도를 높입니다.\n",
    "\n",
    "DataLoader 쉬운 API로 이러한 복잡성 내용을 추상화한 반복자(iterable) 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pmS1YqP1OhH-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLacMc-IOhH_"
   },
   "source": [
    "## DataLoader를 통해 반복\n",
    "해당 데이터 세트를 ``Dataloader``에 로드 했으며 반복할 수 있습니다. 아래의 각 반복은`` train_features`` 및 ``train_labels`` ( batch_size=64 의 feature 및 label) 의 배치를 반환합니다.  ``shuffle=True``를 지정했기 때문에 모든 배치를 반복한 후에 데이터가 섞입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "_I9hsav_OhH_",
    "outputId": "555ff5d8-bb05-4eb5-dd29-4db06ec2f7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 20, 20])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQWUlEQVR4nO3dfaxU9Z3H8c9neVAXSLTLSkVRSCUEYlZkDbaR3aDdIhBT6AK7kM3WNSRoXdAm22RZN7H9R2Ni2CYVgqVbfGxVqlLR3ijEbGIrdSsiIviA7F2ECwhWWJ8wmqvf/WMO5P6uM/C783Bn7vh+JWTmnPOdOb9hkk/OmfO75+uIEAAc9yfNHgCA1kIoAEgQCgAShAKABKEAIDG42QMoxzaXRIAGiwiXW8+RAoAEoQAgUVMo2J5p+w3bu20vL7Pdtn9SbN9ue0ot+wPQeFWHgu1BklZJmiVpkqRFtif1KpslaXzxb4mk1dXuD0D/qOVIYaqk3RHRGRGfSnpI0pxeNXMk3Rclz0s60/Y5NewTQIPVEgrnStrXY7mrWNfXGkmS7SW2t9jeUsOYANSolkuS5S5n9L6UmFNTWhmxRtIaiUuSQDPVcqTQJWlMj+XzJB2oogZAC6klFF6QNN72ONtDJS2UtKFXzQZJ3y2uQnxd0nsRcbCGfQJosKpPHyKi2/ZSSU9LGiRpbUTstH19sf0uSR2SZkvaLemYpGtrHzKARnIr3mSF3xSAxmOaM4AshAKABKEAIEEoAEgQCgAShAKABKEAIEEoAEgQCgAShAKABKEAIEEoAEgQCgAShAKABKEAIEEoAEgQCgAShAKARC0dosbY/i/br9neafumMjXTbb9ne1vx75bahgug0Wrp+9At6V8iYqvtEZJetL0pIl7tVffbiLi6hv0A6EdVHylExMGI2Fo8/0DSa6rQ/QnAwFHLkcIJtsdKukTSf5fZ/A3bL6vUBOYHEbGzwnssUakJLYAqnX/++Vl1b7/9dsVtNYeC7eGSHpX0/Yh4v9fmrZIuiIgPbc+W9GuVOlB/AW3jgNZQ09UH20NUCoRfRMRjvbdHxPsR8WHxvEPSENsja9kngMaq5eqDJf1c0msR8R8Var5a1Mn21GJ/71a7TwCNV8vpw+WS/lHSK7a3FetulnS+dKJt3HxJ37PdLeljSQujFVtSATiBtnFAG+nLD42ffPIJbeMAnBqhACBBKABIEAoAEoQCgERdpjmjPV1//fXZtRdeeGF27d13351du3fv3uzaYcOGZdeOHTs2q27atGnZ7zllypTs2okTJ2bX9kXu1Ycrr7yy4jaOFAAkCAUACUIBQIJQAJAgFAAkCAUACUIBQIJQAJAgFAAkmNH4JXPbbbdl195www3ZtSNGjMiunTFjRnbt8OHDs2svuOCC7NpcxY3DsrTCvUlyv7P9+/dX3MaRAoAEoQAgUevdnPfYfqVoCbelzHbb/ont3ba3287/ixEATVGP3xSuiIg/Vtg2S6U+D+MlXSZpdfEIoEU1+vRhjqT7ouR5SWfaPqfB+wRQg1pDISRttP1i0fatt3Ml7eux3KUK/SZtL7G9pdxpCID+U+vpw+URccD22ZI22X49Ip7tsb3c9Zyy121oGwe0hpqOFCLiQPF4WNJ6SVN7lXRJGtNj+TyVGs0CaFG1tI0bZnvE8eeSZkja0atsg6TvFlchvi7pvYg4WPVoATRcLacPoyStL2Z8DZb0y4h4yvb10om2cR2SZkvaLemYpGtrGy6ARqNtXD867bTTsmuvvTY/P1evXp1d2wrf95EjR7Jrt2zJ/9351Vdfza596aWXsuqee+657Pfs7OzMrm0FEUHbOACnRigASBAKABKEAoAEoQAgQSgASBAKABKEAoAEoQAgQSgASHA35zqYNm1aVt3NN9+c/Z5XXXVVdm1fpi7v2NH7b9Yqe/zxx7NrH3300ezat956K7v26NGj2bWoD44UACQIBQAJQgFAglAAkCAUACQIBQAJQgFAopYbt04o2sUd//e+7e/3qplu+70eNbfUPGIADVX15KWIeEPSZEmyPUjSfpVu897bbyPi6mr3A6B/1ev04ZuS/ici8qeqAWhJ9ZrmvFDSgxW2fcP2yyo1gflBROwsV1S0nSvXeq4pli5dml27YsWKrLrBg/P/u/syvffWW2/Nrr3zzjuza7u7u7Nr0T5qPlKwPVTStyX9qszmrZIuiIiLJd0p6deV3ici1kTEpRFxaa1jAlC9epw+zJK0NSIO9d4QEe9HxIfF8w5JQ2yPrMM+ATRIPUJhkSqcOtj+qosWUranFvt7tw77BNAgNf2mYPtPJX1L0nU91vVsGzdf0vdsd0v6WNLCaIUWRQAqqikUIuKYpD/rte6uHs9XSlpZyz4A9C9mNAJIEAoAEoQCgAShACBBKABIuBWvENpu+qA+//zz7Nrc/8O+TF2eMGFCdu277zL1A30XES63niMFAAlCAUCCUACQIBQAJAgFAAlCAUCCUACQIBQAJAgFAAlCAUCCac4VrFu3Lrt2/vz5dd9/Z2dndu3mzZuza7du3Zpd29HRkV27a9eu7Fq0BqY5A8hyylCwvdb2Yds7eqz7iu1Ntt8sHs+q8NqZtt+wvdv28noOHEBj5Bwp3CNpZq91yyU9ExHjJT1TLCeKVnKrVLoF/CRJi2xPqmm0ABrulKEQEc9KOtJr9RxJ9xbP75U0t8xLp0raHRGdEfGppIeK1wFoYdX+pjAqIg5KUvF4dpmacyXt67HcVawD0MLq1UuynHK/bFa8qtBqvSSBL6tqjxQO2T5HkorHw2VquiSN6bF8nkpNZsuilyTQGqoNhQ2SrimeXyPp8TI1L0gab3tc0YR2YfE6AC0s55Lkg5J+L2mC7S7biyXdLulbtt9UqW3c7UXtaNsdkhQR3ZKWSnpa0muS1lVqQw+gdZzyN4WIWFRh0zfL1B6QNLvHcoek/GlxAJqOac4VjB07Nrt28eLFWXVz587Nfs9Jk/KndBSNvbP05fs+duxYdu327duzax955JHs2gceeCC79p133smuBdOcAWQiFAAkCAUACUIBQIJQAJAgFAAkCAUACUIBQIJQAJAgFAAkmObcj4YMGZJdO3HixIaMYd68edm1fblL9bhx47JrTz/99OzaJ554Irt22bJl2bV79+7Nrm1XTHMGkIVQAJAgFAAkCAUACUIBQIJQAJAgFAAkqu0leYft121vt73e9pkVXrvH9iu2t9neUsdxA2iQantJbpJ0UUT8haRdkv7tJK+/IiIm088BGBiq6iUZERuLW7hL0vMqNXoB0AaypjnbHivpyYi4qMy2JyQ9HBFfuO2u7f+VdFSldnE/jYg1J9lHz7Zxf5k1erSMKVOmZNeuW7cuu7Yv06cfe+yx7NoFCxZk17arStOca+olafvfJXVL+kWFkssj4oDtsyVtsv16ceRRboBrJK0p3rct//YBGAiqvvpg+xpJV0v6h6hwuFE0h1FEHJa0XqX29ABaWFWhYHumpH+V9O2IKNsxxPYw2yOOP5c0Q9KOcrUAWke1vSRXShqh0inBNtt3FbUneklKGiXpd7ZflvQHSb+JiKca8ikA1E21vSR/XqH2RC/JiOiUdHFNowPQ75jRCCBBKABIEAoAEoQCgAShACDB3ZzR70aPHp1du3PnzuzaoUOHZtdedtllWXU7drTv1Bru5gwgC6EAIEEoAEgQCgAShAKABKEAIEEoAEgQCgAShAKARE33aASqkTubUJKGDx+eXfvRRx9l137wwQfZtV82HCkASBAKABLVto37ke39xf0Zt9meXeG1M22/YXu37eX1HDiAxqi2bZwk/bhoBzc5Ijp6b7Q9SNIqSbMkTZK0yPakWgYLoPGqahuXaaqk3RHRGRGfSnpI0pwq3gdAP6rlN4WlRdfptbbPKrP9XEn7eix3FevKsr3E9ha6UwPNVW0orJb0NUmTJR2UtKJMTbkbOFS8eUpErImIS+lODTRXVaEQEYci4rOI+FzSz1S+HVyXpDE9ls+TdKCa/QHoP9W2jTunx+J3VL4d3AuSxtseZ3uopIWSNlSzPwD955QzGou2cdMljbTdJemHkqbbnqzS6cAeSdcVtaMl/WdEzI6IbttLJT0taZCktRGRf8M9AE3BjVvr4Iwzzsiq+/jjjxs8kuY566xyvzWXt3HjxuzaKVOmZNeuXLkyu/amm27Krm1X3LgVQBZCAUCCUACQIBQAJAgFAAlCAUCCUACQIBQAJAgFAAlCAUCCac51cOONN2bV3X///dnvefTo0WqHUzcLFizIrl21alV27ciRI7NrjxzJv7/PJZdckl27b9++Uxe1OaY5A8hCKABIEAoAEoQCgAShACBBKABIEAoAEjn3aFwr6WpJhyPiomLdw5ImFCVnSvq/iJhc5rV7JH0g6TNJ3dy+HWh9Oa3o75G0UtJ9x1dExN8ff257haT3TvL6KyLij9UOEED/OmUoRMSztseW22bbkv5O0pV1HheAJsk5UjiZv5J0KCLerLA9JG0spi3/NCLWVHoj20skLalxPE0xaNCgrLqurq7s97zjjjuyazdv3pxdO2/evOza+fPnZ9f25W7OmzZtyq6dO3dudm073y27P9UaCoskPXiS7ZdHxAHbZ0vaZPv1omHtFxSBsUYaeH/7ALSTqq8+2B4s6W8lPVypJiIOFI+HJa1X+fZyAFpILZck/0bS6xFR9pjY9jDbI44/lzRD5dvLAWghpwyFom3c7yVNsN1le3GxaaF6nTrYHm27o1gcJel3tl+W9AdJv4mIp+o3dACNkHP1YVGF9f9UZt0BSbOL552SLq5xfAD6GTMaASQIBQAJQgFAglAAkCAUACS4m3MdDBkyJKuuL1OXly1bll1b+hOUPH35vnft2pVd++STT2bX3nLLLdm1TF1uHO7mDCALoQAgQSgASBAKABKEAoAEoQAgQSgASBAKABKEAoAEoQAg0arTnN+R9Fav1SMltWP/iHb9XFL7frZ2+FwXRMSfl9vQkqFQju0t7dhhql0/l9S+n61dP9dxnD4ASBAKABIDKRQqdpca4Nr1c0nt+9na9XNJGkC/KQDoHwPpSAFAPyAUACRaPhRsz7T9hu3dtpc3ezz1ZHuP7Vdsb7O9pdnjqZbttbYP297RY91XbG+y/WbxmN+WuoVU+Gw/sr2/+N622Z7dzDHWW0uHgu1BklZJmiVpkqRFtic1d1R1d0VETB7g173vkTSz17rlkp6JiPGSnimWB6J79MXPJkk/Lr63yRHRUWb7gNXSoaBSl+rdEdEZEZ9KekjSnCaPCb1ExLOSjvRaPUfSvcXzeyXN7c8x1UuFz9bWWj0UzpW0r8dyV7GuXYSkjbZftL2k2YOps1ERcVCSisezmzyeeltqe3txejEgT40qafVQKHcL6na6hnp5RExR6fTon23/dbMHhCyrJX1N0mRJByWtaOpo6qzVQ6FL0pgey+dJOtCksdRd0aVbEXFY0nqVTpfaxSHb50hS8Xi4yeOpm4g4FBGfRcTnkn6m9vreWj4UXpA03vY420MlLZS0ocljqgvbw2yPOP5c0gxJO07+qgFlg6RriufXSHq8iWOpq+NhV/iO2ut70+BmD+BkIqLb9lJJT0saJGltROxs8rDqZZSk9UV3p8GSfhkRTzV3SNWx/aCk6ZJG2u6S9ENJt0taZ3uxpL2SFjRvhNWr8Nmm256s0qnsHknXNWt8jcA0ZwCJVj99ANDPCAUACUIBQIJQAJAgFAAkCAUACUIBQOL/AVaRtfg+HPp3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12wfH6alOhH_"
   },
   "source": [
    "## TensorDataset\n",
    "- PyTorch의 TensorDataset은 tensor를 감싸는 Dataset입니다.\n",
    "- TensorDataset은 Dataset을 상속한 클래스로 학습 데이터 X와 레이블 Y를 묶어 놓는 컨테이너입니다.\n",
    "- TensorDataset을 DataLoader에 전달하면 for 루프에서 데이터의 일부분만 간단히 추출할 수 있게 됩니다.  \n",
    "- TensorDataset에는 텐서만 전달할 수 있으며, Variable은 전달할 수 없으니 주의\n",
    "- Dataset은 직접 작성할 수도 있어서 대량의 이미지 파일을 한 번에 메모리에 저장하지 않고 필요할 때마다 읽어서 학습하는 등 다양하게 활용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MahCibPQOhIA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6094, -0.9894,  1.4437, -0.6391],\n",
      "        [-2.6265, -0.7117,  0.5901, -0.4337],\n",
      "        [ 1.1836,  1.1085,  0.7399,  0.1718],\n",
      "        [ 1.2222, -0.9978,  0.0754, -0.5271],\n",
      "        [-1.1823, -0.4400,  0.2510,  0.6357]], dtype=torch.float64)\n",
      "tensor([0, 0, 1, 1, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(5, 4)\n",
    "y = np.random.randint(0, 2, size=5)\n",
    "\n",
    "X_train = torch.from_numpy(x)\n",
    "y_train = torch.from_numpy(y)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "of3qe0vjOhIA",
    "outputId": "2b794759-0e8c-409b-f281-d08019fe4b9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x261b78d5b80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRPFS6ZIOhIA",
    "outputId": "748f9518-b924-4d61-a17a-ed6ae7092884"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x261b78d5fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=2, shuffle=False)\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKJLpcAFOhIB",
    "outputId": "1bd19d17-78a3-4a5e-ca96-02e8de192c84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6094, -0.9894,  1.4437, -0.6391],\n",
       "         [-2.6265, -0.7117,  0.5901, -0.4337]], dtype=torch.float64),\n",
       " tensor([0, 0], dtype=torch.int32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDSXG7epOhIB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "011_Dataset_torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
