{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습\n",
    "\n",
    "### UCI Machine Learning Repository 의 Auto MPG dataset 을 사용하여 Regression 예측 model 작성\n",
    "\n",
    "auto-mpg.data - data file  \n",
    "auto-mpg.names - data 설명 file\n",
    "\n",
    "1. mpg:           continuous  \n",
    "2. cylinders:     multi-valued discrete  \n",
    "3. displacement:  continuous (배기량)   \n",
    "4. horsepower:    continuous  \n",
    "5. weight:        continuous  \n",
    "6. acceleration:  continuous  \n",
    "7. model year:    multi-valued discrete  \n",
    "8. origin:        multi-valued discrete, 1 - USA, 2 - Europe, 3 - Japan  \n",
    "9. car name:      string (unique for each instance)  \n",
    "\n",
    "Missing Attribute Values:  horsepower has 6 missing values  ==> \"?\" 로 들어 있으므로 read_csv 시 nan 으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load 및 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "file_name = \"auto-mpg.data\"\n",
    "\n",
    "with open(file_name, \"wb\") as file:\n",
    "    response = get(url)\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model year  origin  \n",
       "0          70       1  \n",
       "1          70       1  \n",
       "2          70       1  \n",
       "3          70       1  \n",
       "4          70       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin']\n",
    "\n",
    "rawdata = pd.read_csv(file_name, names=column_names, na_values=\"?\", comment=\"\\t\", sep=\" \", skipinitialspace=True)\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.dropna(inplace=True)\n",
    "\n",
    "data = rawdata.copy()\n",
    "\n",
    "data = pd.get_dummies(data, columns=['cylinders', 'origin'])\n",
    "\n",
    "label = data.pop('mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 13) (98, 13) (294,) (98,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.values, label.values, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ts = torch.FloatTensor(X_train)\n",
    "X_test_ts = torch.FloatTensor(X_test)\n",
    "y_train_ts = torch.FloatTensor(y_train).view(-1, 1)\n",
    "y_test_ts = torch.FloatTensor(y_test).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearReg, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = self.fc3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(X_train.shape[1], 1).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(X_train_ts, y_train_ts)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 511.5716\n",
      "epoch 2 loss: 525.9971\n",
      "epoch 3 loss: 1185.4851\n",
      "epoch 4 loss: 394.7651\n",
      "epoch 5 loss: 338.6110\n",
      "epoch 6 loss: 263.2144\n",
      "epoch 7 loss: 337.3478\n",
      "epoch 8 loss: 122.1267\n",
      "epoch 9 loss: 302.5900\n",
      "epoch 10 loss: 68.9583\n",
      "epoch 11 loss: 45.6265\n",
      "epoch 12 loss: 23.0565\n",
      "epoch 13 loss: 12.6802\n",
      "epoch 14 loss: 21.3807\n",
      "epoch 15 loss: 19.7574\n",
      "epoch 16 loss: 41.6049\n",
      "epoch 17 loss: 16.5662\n",
      "epoch 18 loss: 17.3096\n",
      "epoch 19 loss: 16.9741\n",
      "epoch 20 loss: 6.7747\n",
      "epoch 21 loss: 20.4997\n",
      "epoch 22 loss: 8.7134\n",
      "epoch 23 loss: 7.0482\n",
      "epoch 24 loss: 12.4522\n",
      "epoch 25 loss: 2.0076\n",
      "epoch 26 loss: 15.4194\n",
      "epoch 27 loss: 2.1073\n",
      "epoch 28 loss: 6.2577\n",
      "epoch 29 loss: 7.1264\n",
      "epoch 30 loss: 3.4517\n",
      "epoch 31 loss: 3.9190\n",
      "epoch 32 loss: 11.8590\n",
      "epoch 33 loss: 1.3135\n",
      "epoch 34 loss: 8.8165\n",
      "epoch 35 loss: 8.3715\n",
      "epoch 36 loss: 2.7979\n",
      "epoch 37 loss: 2.7604\n",
      "epoch 38 loss: 2.1764\n",
      "epoch 39 loss: 14.2285\n",
      "epoch 40 loss: 0.8796\n",
      "epoch 41 loss: 1.0882\n",
      "epoch 42 loss: 14.3976\n",
      "epoch 43 loss: 34.8281\n",
      "epoch 44 loss: 3.5679\n",
      "epoch 45 loss: 2.3731\n",
      "epoch 46 loss: 3.3532\n",
      "epoch 47 loss: 33.9049\n",
      "epoch 48 loss: 4.6622\n",
      "epoch 49 loss: 7.6981\n",
      "epoch 50 loss: 1.6413\n",
      "epoch 51 loss: 3.3328\n",
      "epoch 52 loss: 1.3179\n",
      "epoch 53 loss: 4.2748\n",
      "epoch 54 loss: 4.7190\n",
      "epoch 55 loss: 2.2474\n",
      "epoch 56 loss: 6.6127\n",
      "epoch 57 loss: 2.3019\n",
      "epoch 58 loss: 9.6875\n",
      "epoch 59 loss: 4.7228\n",
      "epoch 60 loss: 7.1465\n",
      "epoch 61 loss: 2.0863\n",
      "epoch 62 loss: 3.1659\n",
      "epoch 63 loss: 5.1372\n",
      "epoch 64 loss: 26.7286\n",
      "epoch 65 loss: 5.7276\n",
      "epoch 66 loss: 10.8804\n",
      "epoch 67 loss: 2.2397\n",
      "epoch 68 loss: 5.6157\n",
      "epoch 69 loss: 7.0411\n",
      "epoch 70 loss: 2.4360\n",
      "epoch 71 loss: 5.0038\n",
      "epoch 72 loss: 12.2487\n",
      "epoch 73 loss: 1.4437\n",
      "epoch 74 loss: 3.1719\n",
      "epoch 75 loss: 5.6231\n",
      "epoch 76 loss: 38.7150\n",
      "epoch 77 loss: 15.5677\n",
      "epoch 78 loss: 8.2574\n",
      "epoch 79 loss: 9.5694\n",
      "epoch 80 loss: 1.7942\n",
      "epoch 81 loss: 1.3552\n",
      "epoch 82 loss: 15.3881\n",
      "epoch 83 loss: 3.9929\n",
      "epoch 84 loss: 34.0303\n",
      "epoch 85 loss: 4.4684\n",
      "epoch 86 loss: 1.7898\n",
      "epoch 87 loss: 3.0045\n",
      "epoch 88 loss: 2.9340\n",
      "epoch 89 loss: 1.1904\n",
      "epoch 90 loss: 3.6910\n",
      "epoch 91 loss: 4.9074\n",
      "epoch 92 loss: 15.9263\n",
      "epoch 93 loss: 3.9804\n",
      "epoch 94 loss: 1.4559\n",
      "epoch 95 loss: 6.4326\n",
      "epoch 96 loss: 0.7830\n",
      "epoch 97 loss: 4.3960\n",
      "epoch 98 loss: 2.9130\n",
      "epoch 99 loss: 2.4741\n",
      "epoch 100 loss: 5.3969\n",
      "epoch 101 loss: 24.3726\n",
      "epoch 102 loss: 23.7816\n",
      "epoch 103 loss: 9.0374\n",
      "epoch 104 loss: 11.8341\n",
      "epoch 105 loss: 1.9603\n",
      "epoch 106 loss: 3.2222\n",
      "epoch 107 loss: 7.6875\n",
      "epoch 108 loss: 3.0419\n",
      "epoch 109 loss: 10.4095\n",
      "epoch 110 loss: 9.8953\n",
      "epoch 111 loss: 30.8067\n",
      "epoch 112 loss: 1.0945\n",
      "epoch 113 loss: 9.3126\n",
      "epoch 114 loss: 9.0347\n",
      "epoch 115 loss: 3.2294\n",
      "epoch 116 loss: 9.5731\n",
      "epoch 117 loss: 13.2362\n",
      "epoch 118 loss: 4.3021\n",
      "epoch 119 loss: 7.3491\n",
      "epoch 120 loss: 3.1372\n",
      "epoch 121 loss: 7.4177\n",
      "epoch 122 loss: 8.2001\n",
      "epoch 123 loss: 10.8501\n",
      "epoch 124 loss: 2.7680\n",
      "epoch 125 loss: 6.6465\n",
      "epoch 126 loss: 10.7286\n",
      "epoch 127 loss: 1.7141\n",
      "epoch 128 loss: 2.0024\n",
      "epoch 129 loss: 1.8346\n",
      "epoch 130 loss: 4.3461\n",
      "epoch 131 loss: 3.7955\n",
      "epoch 132 loss: 5.0425\n",
      "epoch 133 loss: 10.0282\n",
      "epoch 134 loss: 2.0719\n",
      "epoch 135 loss: 1.2155\n",
      "epoch 136 loss: 7.7585\n",
      "epoch 137 loss: 6.7629\n",
      "epoch 138 loss: 34.4464\n",
      "epoch 139 loss: 3.1952\n",
      "epoch 140 loss: 9.4544\n",
      "epoch 141 loss: 2.1266\n",
      "epoch 142 loss: 4.2440\n",
      "epoch 143 loss: 5.7564\n",
      "epoch 144 loss: 1.6990\n",
      "epoch 145 loss: 1.9254\n",
      "epoch 146 loss: 12.8311\n",
      "epoch 147 loss: 1.6864\n",
      "epoch 148 loss: 1.5368\n",
      "epoch 149 loss: 8.1269\n",
      "epoch 150 loss: 2.4531\n",
      "epoch 151 loss: 2.1498\n",
      "epoch 152 loss: 6.5608\n",
      "epoch 153 loss: 7.9677\n",
      "epoch 154 loss: 4.7845\n",
      "epoch 155 loss: 3.6617\n",
      "epoch 156 loss: 5.2557\n",
      "epoch 157 loss: 3.2046\n",
      "epoch 158 loss: 3.5656\n",
      "epoch 159 loss: 6.4725\n",
      "epoch 160 loss: 2.5445\n",
      "epoch 161 loss: 1.7939\n",
      "epoch 162 loss: 31.5484\n",
      "epoch 163 loss: 12.3157\n",
      "epoch 164 loss: 1.3170\n",
      "epoch 165 loss: 0.6727\n",
      "epoch 166 loss: 2.9409\n",
      "epoch 167 loss: 8.0196\n",
      "epoch 168 loss: 1.2816\n",
      "epoch 169 loss: 10.3086\n",
      "epoch 170 loss: 4.3250\n",
      "epoch 171 loss: 1.4671\n",
      "epoch 172 loss: 2.1002\n",
      "epoch 173 loss: 3.7289\n",
      "epoch 174 loss: 6.2743\n",
      "epoch 175 loss: 1.4336\n",
      "epoch 176 loss: 5.7598\n",
      "epoch 177 loss: 2.6949\n",
      "epoch 178 loss: 5.5518\n",
      "epoch 179 loss: 34.9989\n",
      "epoch 180 loss: 1.4627\n",
      "epoch 181 loss: 4.6209\n",
      "epoch 182 loss: 0.7923\n",
      "epoch 183 loss: 3.9866\n",
      "epoch 184 loss: 2.8299\n",
      "epoch 185 loss: 10.2070\n",
      "epoch 186 loss: 2.8464\n",
      "epoch 187 loss: 1.8403\n",
      "epoch 188 loss: 2.0439\n",
      "epoch 189 loss: 13.7090\n",
      "epoch 190 loss: 2.1344\n",
      "epoch 191 loss: 2.2487\n",
      "epoch 192 loss: 1.8653\n",
      "epoch 193 loss: 1.4784\n",
      "epoch 194 loss: 2.7428\n",
      "epoch 195 loss: 2.5821\n",
      "epoch 196 loss: 1.8113\n",
      "epoch 197 loss: 2.2383\n",
      "epoch 198 loss: 1.5796\n",
      "epoch 199 loss: 5.2001\n",
      "epoch 200 loss: 4.8233\n",
      "epoch 201 loss: 5.1955\n",
      "epoch 202 loss: 2.6929\n",
      "epoch 203 loss: 3.7876\n",
      "epoch 204 loss: 0.9748\n",
      "epoch 205 loss: 3.4518\n",
      "epoch 206 loss: 2.0663\n",
      "epoch 207 loss: 3.6395\n",
      "epoch 208 loss: 3.5776\n",
      "epoch 209 loss: 0.6596\n",
      "epoch 210 loss: 6.8819\n",
      "epoch 211 loss: 2.8316\n",
      "epoch 212 loss: 2.0696\n",
      "epoch 213 loss: 2.9471\n",
      "epoch 214 loss: 1.0553\n",
      "epoch 215 loss: 26.7487\n",
      "epoch 216 loss: 28.2091\n",
      "epoch 217 loss: 5.0019\n",
      "epoch 218 loss: 2.3812\n",
      "epoch 219 loss: 7.4439\n",
      "epoch 220 loss: 1.5807\n",
      "epoch 221 loss: 6.6549\n",
      "epoch 222 loss: 3.6293\n",
      "epoch 223 loss: 7.8008\n",
      "epoch 224 loss: 1.9042\n",
      "epoch 225 loss: 1.5599\n",
      "epoch 226 loss: 4.1097\n",
      "epoch 227 loss: 1.2368\n",
      "epoch 228 loss: 1.6038\n",
      "epoch 229 loss: 8.2796\n",
      "epoch 230 loss: 0.8118\n",
      "epoch 231 loss: 7.4845\n",
      "epoch 232 loss: 2.3412\n",
      "epoch 233 loss: 2.0794\n",
      "epoch 234 loss: 9.3275\n",
      "epoch 235 loss: 9.7006\n",
      "epoch 236 loss: 1.0165\n",
      "epoch 237 loss: 7.4734\n",
      "epoch 238 loss: 1.0329\n",
      "epoch 239 loss: 3.2501\n",
      "epoch 240 loss: 2.6395\n",
      "epoch 241 loss: 4.4910\n",
      "epoch 242 loss: 8.1795\n",
      "epoch 243 loss: 4.6364\n",
      "epoch 244 loss: 7.9611\n",
      "epoch 245 loss: 7.1038\n",
      "epoch 246 loss: 8.2639\n",
      "epoch 247 loss: 3.3643\n",
      "epoch 248 loss: 1.7428\n",
      "epoch 249 loss: 5.2956\n",
      "epoch 250 loss: 3.3369\n",
      "epoch 251 loss: 6.6368\n",
      "epoch 252 loss: 5.2497\n",
      "epoch 253 loss: 2.2768\n",
      "epoch 254 loss: 3.7391\n",
      "epoch 255 loss: 6.7752\n",
      "epoch 256 loss: 1.3469\n",
      "epoch 257 loss: 2.8096\n",
      "epoch 258 loss: 4.4736\n",
      "epoch 259 loss: 6.0533\n",
      "epoch 260 loss: 1.4287\n",
      "epoch 261 loss: 1.7628\n",
      "epoch 262 loss: 1.4640\n",
      "epoch 263 loss: 25.8111\n",
      "epoch 264 loss: 5.9522\n",
      "epoch 265 loss: 8.7381\n",
      "epoch 266 loss: 25.9846\n",
      "epoch 267 loss: 2.3177\n",
      "epoch 268 loss: 0.4635\n",
      "epoch 269 loss: 0.5913\n",
      "epoch 270 loss: 3.1503\n",
      "epoch 271 loss: 0.6675\n",
      "epoch 272 loss: 9.1926\n",
      "epoch 273 loss: 2.1223\n",
      "epoch 274 loss: 3.1913\n",
      "epoch 275 loss: 2.7398\n",
      "epoch 276 loss: 3.5330\n",
      "epoch 277 loss: 28.4786\n",
      "epoch 278 loss: 2.6767\n",
      "epoch 279 loss: 2.1997\n",
      "epoch 280 loss: 1.9634\n",
      "epoch 281 loss: 5.8014\n",
      "epoch 282 loss: 6.1451\n",
      "epoch 283 loss: 4.5544\n",
      "epoch 284 loss: 3.2023\n",
      "epoch 285 loss: 3.8258\n",
      "epoch 286 loss: 2.5172\n",
      "epoch 287 loss: 3.4302\n",
      "epoch 288 loss: 3.5990\n",
      "epoch 289 loss: 13.2787\n",
      "epoch 290 loss: 1.1070\n",
      "epoch 291 loss: 1.5805\n",
      "epoch 292 loss: 6.7426\n",
      "epoch 293 loss: 3.4817\n",
      "epoch 294 loss: 7.0531\n",
      "epoch 295 loss: 1.4716\n",
      "epoch 296 loss: 4.1022\n",
      "epoch 297 loss: 2.4708\n",
      "epoch 298 loss: 3.2573\n",
      "epoch 299 loss: 0.3037\n",
      "epoch 300 loss: 3.8088\n",
      "epoch 301 loss: 3.7737\n",
      "epoch 302 loss: 10.0913\n",
      "epoch 303 loss: 1.0718\n",
      "epoch 304 loss: 2.0720\n",
      "epoch 305 loss: 8.1327\n",
      "epoch 306 loss: 4.5142\n",
      "epoch 307 loss: 0.9084\n",
      "epoch 308 loss: 1.1492\n",
      "epoch 309 loss: 7.9287\n",
      "epoch 310 loss: 6.7782\n",
      "epoch 311 loss: 3.3154\n",
      "epoch 312 loss: 3.4088\n",
      "epoch 313 loss: 5.4676\n",
      "epoch 314 loss: 2.9962\n",
      "epoch 315 loss: 7.5158\n",
      "epoch 316 loss: 1.3775\n",
      "epoch 317 loss: 3.8228\n",
      "epoch 318 loss: 1.8176\n",
      "epoch 319 loss: 4.6635\n",
      "epoch 320 loss: 7.6578\n",
      "epoch 321 loss: 5.1962\n",
      "epoch 322 loss: 8.4914\n",
      "epoch 323 loss: 6.3045\n",
      "epoch 324 loss: 1.6778\n",
      "epoch 325 loss: 4.1522\n",
      "epoch 326 loss: 2.2188\n",
      "epoch 327 loss: 4.7425\n",
      "epoch 328 loss: 0.7023\n",
      "epoch 329 loss: 3.2577\n",
      "epoch 330 loss: 1.1756\n",
      "epoch 331 loss: 2.2342\n",
      "epoch 332 loss: 3.5522\n",
      "epoch 333 loss: 34.2390\n",
      "epoch 334 loss: 4.3579\n",
      "epoch 335 loss: 1.6636\n",
      "epoch 336 loss: 0.1349\n",
      "epoch 337 loss: 1.8179\n",
      "epoch 338 loss: 11.8814\n",
      "epoch 339 loss: 0.9794\n",
      "epoch 340 loss: 2.5040\n",
      "epoch 341 loss: 2.0375\n",
      "epoch 342 loss: 1.4931\n",
      "epoch 343 loss: 3.4852\n",
      "epoch 344 loss: 2.0022\n",
      "epoch 345 loss: 1.1008\n",
      "epoch 346 loss: 2.1635\n",
      "epoch 347 loss: 4.3545\n",
      "epoch 348 loss: 3.3849\n",
      "epoch 349 loss: 3.1663\n",
      "epoch 350 loss: 1.2986\n",
      "epoch 351 loss: 3.8088\n",
      "epoch 352 loss: 5.7503\n",
      "epoch 353 loss: 2.5697\n",
      "epoch 354 loss: 4.2657\n",
      "epoch 355 loss: 5.1984\n",
      "epoch 356 loss: 26.8762\n",
      "epoch 357 loss: 5.7595\n",
      "epoch 358 loss: 2.1481\n",
      "epoch 359 loss: 3.7665\n",
      "epoch 360 loss: 2.0487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 361 loss: 14.8581\n",
      "epoch 362 loss: 3.6815\n",
      "epoch 363 loss: 2.6497\n",
      "epoch 364 loss: 1.6979\n",
      "epoch 365 loss: 0.4026\n",
      "epoch 366 loss: 4.3669\n",
      "epoch 367 loss: 7.3417\n",
      "epoch 368 loss: 1.1349\n",
      "epoch 369 loss: 2.6053\n",
      "epoch 370 loss: 1.1789\n",
      "epoch 371 loss: 7.2141\n",
      "epoch 372 loss: 9.0227\n",
      "epoch 373 loss: 1.1389\n",
      "epoch 374 loss: 28.0601\n",
      "epoch 375 loss: 0.4840\n",
      "epoch 376 loss: 5.4292\n",
      "epoch 377 loss: 6.0250\n",
      "epoch 378 loss: 0.2213\n",
      "epoch 379 loss: 2.6202\n",
      "epoch 380 loss: 3.9057\n",
      "epoch 381 loss: 8.3364\n",
      "epoch 382 loss: 1.0410\n",
      "epoch 383 loss: 1.4132\n",
      "epoch 384 loss: 1.0892\n",
      "epoch 385 loss: 2.5152\n",
      "epoch 386 loss: 5.3967\n",
      "epoch 387 loss: 1.4831\n",
      "epoch 388 loss: 1.1720\n",
      "epoch 389 loss: 1.5123\n",
      "epoch 390 loss: 6.5008\n",
      "epoch 391 loss: 3.8870\n",
      "epoch 392 loss: 0.9370\n",
      "epoch 393 loss: 1.2921\n",
      "epoch 394 loss: 2.6043\n",
      "epoch 395 loss: 2.6170\n",
      "epoch 396 loss: 1.5010\n",
      "epoch 397 loss: 1.1227\n",
      "epoch 398 loss: 6.5570\n",
      "epoch 399 loss: 2.8103\n",
      "epoch 400 loss: 5.7476\n",
      "epoch 401 loss: 8.1282\n",
      "epoch 402 loss: 0.9637\n",
      "epoch 403 loss: 2.6075\n",
      "epoch 404 loss: 1.1528\n",
      "epoch 405 loss: 6.7700\n",
      "epoch 406 loss: 2.6344\n",
      "epoch 407 loss: 5.8110\n",
      "epoch 408 loss: 2.2697\n",
      "epoch 409 loss: 1.8403\n",
      "epoch 410 loss: 0.9182\n",
      "epoch 411 loss: 3.3930\n",
      "epoch 412 loss: 1.6955\n",
      "epoch 413 loss: 0.9523\n",
      "epoch 414 loss: 0.6139\n",
      "epoch 415 loss: 0.5479\n",
      "epoch 416 loss: 1.8314\n",
      "epoch 417 loss: 2.7905\n",
      "epoch 418 loss: 1.9596\n",
      "epoch 419 loss: 2.2659\n",
      "epoch 420 loss: 10.3609\n",
      "epoch 421 loss: 7.9314\n",
      "epoch 422 loss: 1.5487\n",
      "epoch 423 loss: 1.2087\n",
      "epoch 424 loss: 1.8502\n",
      "epoch 425 loss: 1.6302\n",
      "epoch 426 loss: 10.8230\n",
      "epoch 427 loss: 5.6602\n",
      "epoch 428 loss: 9.1432\n",
      "epoch 429 loss: 1.6565\n",
      "epoch 430 loss: 2.8832\n",
      "epoch 431 loss: 6.6363\n",
      "epoch 432 loss: 2.3609\n",
      "epoch 433 loss: 0.5157\n",
      "epoch 434 loss: 4.3455\n",
      "epoch 435 loss: 3.1169\n",
      "epoch 436 loss: 14.3422\n",
      "epoch 437 loss: 0.9602\n",
      "epoch 438 loss: 4.8590\n",
      "epoch 439 loss: 2.0927\n",
      "epoch 440 loss: 1.4044\n",
      "epoch 441 loss: 5.6050\n",
      "epoch 442 loss: 1.4706\n",
      "epoch 443 loss: 2.0358\n",
      "epoch 444 loss: 4.1378\n",
      "epoch 445 loss: 1.9029\n",
      "epoch 446 loss: 25.6748\n",
      "epoch 447 loss: 11.5223\n",
      "epoch 448 loss: 0.4399\n",
      "epoch 449 loss: 9.4758\n",
      "epoch 450 loss: 4.2816\n",
      "epoch 451 loss: 1.8135\n",
      "epoch 452 loss: 2.0949\n",
      "epoch 453 loss: 4.1968\n",
      "epoch 454 loss: 7.2455\n",
      "epoch 455 loss: 1.2356\n",
      "epoch 456 loss: 8.7948\n",
      "epoch 457 loss: 1.5661\n",
      "epoch 458 loss: 1.7220\n",
      "epoch 459 loss: 4.6409\n",
      "epoch 460 loss: 1.6549\n",
      "epoch 461 loss: 2.9177\n",
      "epoch 462 loss: 1.6242\n",
      "epoch 463 loss: 4.4274\n",
      "epoch 464 loss: 0.8631\n",
      "epoch 465 loss: 2.9429\n",
      "epoch 466 loss: 5.4643\n",
      "epoch 467 loss: 2.9893\n",
      "epoch 468 loss: 2.5248\n",
      "epoch 469 loss: 7.1601\n",
      "epoch 470 loss: 2.2988\n",
      "epoch 471 loss: 1.0710\n",
      "epoch 472 loss: 3.9227\n",
      "epoch 473 loss: 1.9445\n",
      "epoch 474 loss: 3.5420\n",
      "epoch 475 loss: 2.8350\n",
      "epoch 476 loss: 2.4955\n",
      "epoch 477 loss: 1.1788\n",
      "epoch 478 loss: 0.4879\n",
      "epoch 479 loss: 3.3192\n",
      "epoch 480 loss: 2.1656\n",
      "epoch 481 loss: 4.9731\n",
      "epoch 482 loss: 6.3296\n",
      "epoch 483 loss: 1.1306\n",
      "epoch 484 loss: 4.4438\n",
      "epoch 485 loss: 2.0408\n",
      "epoch 486 loss: 1.5389\n",
      "epoch 487 loss: 1.7367\n",
      "epoch 488 loss: 1.2991\n",
      "epoch 489 loss: 0.7555\n",
      "epoch 490 loss: 0.6281\n",
      "epoch 491 loss: 3.3248\n",
      "epoch 492 loss: 1.9024\n",
      "epoch 493 loss: 1.7283\n",
      "epoch 494 loss: 5.6675\n",
      "epoch 495 loss: 9.7082\n",
      "epoch 496 loss: 6.7904\n",
      "epoch 497 loss: 3.2859\n",
      "epoch 498 loss: 2.0241\n",
      "epoch 499 loss: 26.3792\n",
      "epoch 500 loss: 7.2954\n"
     ]
    }
   ],
   "source": [
    "Loss = []\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch {} loss: {:.4f}\".format(epoch + 1, loss.item()))\n",
    "    Loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test_ts.to(device)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $r^2$ 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8573409022307047"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28bea586880>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_test[:, 0], y_test, c='b', label=\"true\")\n",
    "plt.scatter(X_test[:, 0], y_pred, c='r', label=\"prediction\")\n",
    "plt.xlabel('cylinders')\n",
    "plt.ylabel('mpg')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
